{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised - Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor, GradientBoostingRegressor, AdaBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = datasets.load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split and standardize data \n",
    "X_train, X_test, y_train, y_test = train_test_split(boston.data, boston.target)\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For comparing rmse's across models. You could calculate another error metric or use sklearn's .score which outputs R^2 \n",
    "def rmse(true, predicted):\n",
    "    return np.sqrt(np.mean((true - predicted) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree RMSE: 4.174302714179495\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "dt = DecisionTreeRegressor()\n",
    "dt.fit(X_train, y_train)\n",
    "dt_preds = dt.predict(X_test)\n",
    "print('Decision Tree RMSE: {}'.format(rmse(dt_preds, y_test)))\n",
    "\n",
    "#documentation: http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest RMSE: 3.1322610132487543\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X_train, y_train)\n",
    "rf_preds = rf.predict(X_test)\n",
    "print('Random Forest RMSE: {}'.format(rmse(rf_preds, y_test)))\n",
    "\n",
    "#documentation: http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging RMSE: 3.5952272605661673\n"
     ]
    }
   ],
   "source": [
    "# Bagging\n",
    "bag = BaggingRegressor()\n",
    "bag.fit(X_train, y_train)\n",
    "bag_preds = bag.predict(X_test)\n",
    "print('Bagging RMSE: {}'.format(rmse(bag_preds, y_test)))\n",
    "\n",
    "#documentation: http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingRegressor.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN RMSE: 4.55045243056497\n"
     ]
    }
   ],
   "source": [
    "# K Nearest Neighbors\n",
    "knn = KNeighborsRegressor()\n",
    "knn.fit(X_train, y_train)\n",
    "knn_preds = knn.predict(X_test)\n",
    "print('KNN RMSE: {}'.format(rmse(knn_preds, y_test)))\n",
    "\n",
    "#documentation: http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting RMSE: 2.797881262738919\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting\n",
    "boost = GradientBoostingRegressor()\n",
    "boost.fit(X_train, y_train)\n",
    "boost_preds = boost.predict(X_test)\n",
    "\n",
    "print('Gradient Boosting RMSE: {}'.format(rmse(boost_preds, y_test)))\n",
    "#documentation: http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost RMSE: 3.6367482080683726\n"
     ]
    }
   ],
   "source": [
    "# Adaboost\n",
    "ada = AdaBoostRegressor()\n",
    "ada.fit(X_train, y_train)\n",
    "ada_preds = ada.predict(X_test)\n",
    "\n",
    "print('AdaBoost RMSE: {}'.format(rmse(ada_preds, y_test)))\n",
    "#documentation: http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostRegressor.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised - Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
    "from sklearn.model_selection import KFold, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer = datasets.load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, stratify=cancer.target)\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.9370629370629371\n",
      "Decision Tree Recall: 0.9550561797752809\n",
      "Decision Tree Precision: 0.9444444444444444\n"
     ]
    }
   ],
   "source": [
    "# Decision tree\n",
    "dt = DecisionTreeClassifier(criterion=\"gini\", splitter=\"best\")\n",
    "dt.fit(X_train, y_train)\n",
    "dt_preds = dt.predict(X_test)\n",
    "\n",
    "print('Decision Tree Accuracy: {}'.format(accuracy_score(dt_preds, y_test)))\n",
    "print('Decision Tree Recall: {}'.format(recall_score(dt_preds, y_test)))\n",
    "print('Decision Tree Precision: {}'.format(precision_score(dt_preds, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.986013986013986\n",
      "Random Forest Recall: 1.0\n",
      "Random Forest Precision: 0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=10, criterion=\"gini\", max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=\"auto\", max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=1, random_state=None, verbose=0, warm_start=False, class_weight=None)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "rf_preds = rf.predict(X_test)\n",
    "\n",
    "print('Random Forest Accuracy: {}'.format(accuracy_score(rf_preds, y_test)))\n",
    "print('Random Forest Recall: {}'.format(recall_score(rf_preds, y_test)))\n",
    "print('Random Forest Precision: {}'.format(precision_score(rf_preds, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Accuracy: 0.9790209790209791\n",
      "Bagging Recall: 0.9887640449438202\n",
      "Bagging Precision: 0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "# Bagging\n",
    "bag = BaggingClassifier(base_estimator=None, n_estimators=10, max_samples=1.0, max_features=1.0, bootstrap=True, bootstrap_features=False, oob_score=False, warm_start=False, n_jobs=1, random_state=None, verbose=0)\n",
    "\n",
    "bag.fit(X_train, y_train)\n",
    "bag_preds = bag.predict(X_test)\n",
    "\n",
    "print('Bagging Accuracy: {}'.format(accuracy_score(bag_preds, y_test)))\n",
    "print('Bagging Recall: {}'.format(recall_score(bag_preds, y_test)))\n",
    "print('Bagging Precision: {}'.format(precision_score(bag_preds, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy: 0.9790209790209791\n",
      "KNN Recall: 0.978021978021978\n",
      "KNN Precision: 0.9888888888888889\n"
     ]
    }
   ],
   "source": [
    "# K Nearest Neighbors\n",
    "knn = KNeighborsClassifier(n_neighbors=5, weights=\"uniform\", algorithm=\"auto\", leaf_size=30, p=2, metric=\"minkowski\", metric_params=None, n_jobs=1)\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "knn_preds = knn.predict(X_test)\n",
    "\n",
    "print('KNN Accuracy: {}'.format(accuracy_score(knn_preds, y_test)))\n",
    "print('KNN Recall: {}'.format(recall_score(knn_preds, y_test)))\n",
    "print('KNN Precision: {}'.format(precision_score(knn_preds, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Accuracy: 0.986013986013986\n",
      "Gradient Boosting Recall: 0.9888888888888889\n",
      "Gradient Boosting Precision: 0.9888888888888889\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting\n",
    "boost = GradientBoostingClassifier(loss=\"deviance\", learning_rate=0.1, n_estimators=100, subsample=1.0, criterion=\"friedman_mse\", min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_depth=3, min_impurity_decrease=0.0, min_impurity_split=None, init=None, random_state=None, max_features=None, verbose=0, max_leaf_nodes=None, warm_start=False, presort=\"auto\")\n",
    "\n",
    "boost.fit(X_train, y_train)\n",
    "boost_preds = boost.predict(X_test)\n",
    "print('Gradient Boosting Accuracy: {}'.format(accuracy_score(boost_preds, y_test)))\n",
    "print('Gradient Boosting Recall: {}'.format(recall_score(boost_preds, y_test)))\n",
    "print('Gradient Boosting Precision: {}'.format(precision_score(boost_preds, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Accuracy: 0.993006993006993\n",
      "AdaBoost Recall: 1.0\n",
      "AdaBoost Precision: 0.9888888888888889\n"
     ]
    }
   ],
   "source": [
    "# Adaboost\n",
    "ada = AdaBoostClassifier(base_estimator=None, n_estimators=50, learning_rate=1.0, algorithm=\"SAMME.R\", random_state=None)\n",
    "ada.fit(X_train, y_train)\n",
    "ada_preds = ada.predict(X_test)\n",
    "print('AdaBoost Accuracy: {}'.format(accuracy_score(ada_preds, y_test)))\n",
    "print('AdaBoost Recall: {}'.format(recall_score(ada_preds, y_test)))\n",
    "print('AdaBoost Precision: {}'.format(precision_score(ada_preds, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=-1)]: Done  72 out of  72 | elapsed:   12.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ADA Accuracy: 0.993006993006993\n",
      "Best ADA Recall: 1.0\n",
      "Best ADA Precision: 0.9888888888888889\n"
     ]
    }
   ],
   "source": [
    "# Decide Best model\n",
    "# Grid search for best params\n",
    "\n",
    "# ada example\n",
    "ada_boost_grid = {'n_estimators': [50, 100, 150, 200],\n",
    "                      'random_state': [1, None],\n",
    "                      'learning_rate': [0.1, .5, 1]}\n",
    "\n",
    "ada_gridsearch = GridSearchCV(AdaBoostClassifier(),\n",
    "                             ada_boost_grid,\n",
    "                             n_jobs=-1,\n",
    "                             verbose=True)\n",
    "ada_gridsearch.fit(X_train, y_train)\n",
    "\n",
    "best_ada_model = ada_gridsearch.best_estimator_\n",
    "best_ada_model.fit(X_train, y_train)\n",
    "best_ada_preds = best_ada_model.predict(X_test)\n",
    "\n",
    "print(\"Best ADA Accuracy: {}\".format(accuracy_score(best_ada_preds, y_test)))\n",
    "print(\"Best ADA Recall: {}\".format(recall_score(best_ada_preds, y_test)))\n",
    "print(\"Best ADA Precision: {}\".format(precision_score(best_ada_preds, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X_iris = iris.data\n",
    "y_iris = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target)\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual labels for training set: [2 1 1 0 1 1 1 0 1 2 1 2 0 2 2 2 1 1 2 0 1 2 2 1 2 2 1 2 1 2 2 0 0 2 2 0 0\n",
      " 0 2 2 1 1 1 1 2 2 1 2 0 0 2 0 1 2 1 1 0 2 1 0 0 2 1 2 2 1 1 2 1 1 1 0 2 1\n",
      " 1 2 0 1 0 1 1 0 1 2 0 1 2 1 2 1 0 1 0 2 0 2 1 1 2 2 0 0 1 0 2 1 1 0 2 1 0\n",
      " 0]\n",
      "Predicted labels for training set: [0 1 1 2 0 0 0 2 1 1 0 1 2 1 1 0 0 0 1 2 1 1 1 1 1 1 0 1 0 1 1 2 2 1 1 2 2\n",
      " 2 0 0 0 0 0 1 0 0 0 0 2 2 1 2 0 0 0 0 2 1 0 2 2 1 0 1 1 0 0 0 1 0 0 2 1 0\n",
      " 0 1 2 0 2 0 0 2 1 1 2 0 0 0 1 0 2 1 2 0 2 1 0 1 1 1 2 2 1 2 0 1 0 2 1 0 2\n",
      " 2]\n",
      "Actual labels for test set: [1 0 0 0 0 0 0 1 0 0 0 2 0 2 2 1 2 1 2 0 0 0 0 0 0 2 0 2 0 2 2 2 1 0 0 0 2\n",
      " 1]\n",
      "Predicted labels for training set: [0 2 2 2 2 2 2 0 2 2 2 1 2 1 1 0 1 0 0 2 2 2 2 2 2 1 2 1 2 0 1 1 0 2 2 2 1\n",
      " 0]\n",
      "(38,)\n",
      "(38,)\n"
     ]
    }
   ],
   "source": [
    "#k Means\n",
    "k_means = KMeans(n_clusters=3) \n",
    "k_means.fit(X_train)\n",
    "y_preds = k_means.predict(X_test)\n",
    "print('Actual labels for training set: {}'.format(y_train))\n",
    "print('Predicted labels for training set: {}'.format(k_means.labels_))\n",
    "\n",
    "print('Actual labels for test set: {}'.format(y_test))\n",
    "print('Predicted labels for training set: {}'.format(y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
