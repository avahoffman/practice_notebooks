{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning & Wrangling\n",
    "mostly using pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if a document:\n",
    "df = pd.read_csv(\"document.csv\", #specific things youd like to include based on the data in csv)\n",
    "\n",
    "#Naming columns for a dataframe\n",
    "colnames= ['column1', 'column2', 'etc']\n",
    "\n",
    "test_data = pd.read_csv(url)\n",
    "#if a csv link\n",
    "url = 'https://entire_url'\n",
    "df = pd.read_csv(url #can also specify arguments in here)\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#counting the number of rows in your data\n",
    "number_of_samples = df.count()\n",
    "\n",
    "#viewing it\n",
    "print(\"Number of samples:\", str(number_of_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check out your data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape #number of rows X # columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info() #all the info (col names, dtypes, row #, missing values) \n",
    "# remember that nulls may still be present but just not detectable as such by Pandas (e.g. a \"?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10) #first ten rows\n",
    "df.tail(100) #last 100 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe #descriptive stats for the df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns #what are the column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count() #count for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.column_name.max()\n",
    "df.column_name.min()\n",
    "df.column_name.mean()\n",
    "df.column_name.median()\n",
    "df.column_name.mode()\n",
    "df.column_name.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Series, DataFrames and Indices\n",
    "\n",
    "Pandas Series: Basically it is one column of the DataFrame. (An indexed, one-dimensional array with a dtype (int, float, str, etc.).\n",
    "\n",
    "Conversely, a Pandas DF is a collection of Series with a common index (or joined on the index if you join series to a df or join multiple series to create a df). Each series can have a diff. dtype.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking out a series from a df\n",
    "df['column_name'].head(5)\n",
    "\n",
    "#checking out more than one from a df\n",
    "df[['colName', 'colName']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting index to list to see first 10 elements\n",
    "list(df.index)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at rows 3-9\n",
    "df[3:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at specific columns and rows using their numerical (indexed) location (iloc)\n",
    "# dataframe.iloc[start_row_index:not_inclusive_end_row_index, start_col_index:not_inclusive_end_col_index,]\n",
    "df.iloc[3:5, 2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUT WAIT This one is odd for python, the end of the range IS inclusive in this case (when you use .loc)\n",
    "#mixing it up with row numbers and column names wooooooiiiieee\n",
    "df.loc[3:5, ['colName','colName2']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering the info to view specific data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering is done by passing a Boolean Series to the DataFrame. \n",
    "This Boolean Series can be generated by applying operations to other Series in the DataFrame and can be combined in many ways.\n",
    "\n",
    "AND is given by &\n",
    "OR is given by |\n",
    "NOT is given by ~\n",
    "\n",
    "Parentheses are important --these operators take precedence. \n",
    "A > 1 & B > 2 will be parsed as A > (1 & B) > 2 , this will fail because 1 & B doesn't mean anything alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.year > 2014 ).head() #returns a Boolean for every value of rows in the head for which the year column is > 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#But, if you do this:\n",
    "\n",
    "df[df.year >= 2014].head(15)\n",
    "\n",
    "#You will get a df (with all the columns) with the first 15 rows of the dataframe for which the year column\n",
    "is >= 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combining filters\n",
    "\n",
    "df[(df.year >= 2014) & (df.species == 'Gorilla gorilla') & ~(df.subspecies == 'berengei')].head(10)\n",
    "# Give me the first ten rows in the df where the year is >= 2014 AND the species is Gorilla gorilla \n",
    "# AND the subspecies is NOT berengei \n",
    "# G.g. berengei are Mountain Gorillas :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change values using a filter\n",
    "#AHH 2024 should have been 2014, here is how I fix this\n",
    "myfilter = (df.year == 2024)\n",
    "df.loc[myfilter, 'year'] = 2014 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop it like it's hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['year'], axis=1).head(5) #show me first 5 rows with year column dropped\n",
    "df=df.drop(['year'], axis=1) #drop the entire year column from the whole df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates in a column\n",
    "df[['year']].drop_duplicates().head(10) # show me first 10 unique years in the df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all rows with Na values\n",
    "df.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by these columns first by the column values then by the rows (the [1,0])\n",
    "df.sort_values(by = ['year', 'species'], ascending = [1, 0]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill NA - Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(-1).head() #fill missing values with -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# are there any missing values? returns boolean\n",
    "df.isna()\n",
    "df.isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging data frames\n",
    "combined_df = pd.merge(df1, df2, on='column_with_matching_data_in_both_dfs', how='outer')\n",
    "\n",
    "# outer keeps all rows\n",
    "# and will fill in missing data with NaNs, inner will only have rows of df1 and the matches that were in df2 \n",
    "# (anything in df2 that isn't in the column you matched on in df1 will not be included)\n",
    "\n",
    "# good to check and make sure you did this correctly, e.g. if you want ALL the samples, make sure the new (merged) \n",
    "# df has the same count as the df (df1 or df2) with the larger # of rows\n",
    "\n",
    "#check\n",
    "num_combined = combined_df.count()\n",
    "print('Number of combined:', str(num_combined))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a column with new values based on values in another column \n",
    "\n",
    "def label_col (row):\n",
    "   if row['up_to_date'] == 1 :\n",
    "      return 0\n",
    "   if row['up_to_date'] == 0 :\n",
    "      return 1\n",
    "   \n",
    "df.apply (lambda row: label_col (row),axis=1)\n",
    "#if you like the results then run it again and create a new col in the df with the results:\n",
    "df['new_col'] = df.apply (lambda row: label_col (row),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphs and Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to visualize distributions\n",
    "def plot_with_fill(x, y, label):\n",
    "    lines = plt.plot(x, y, label=label, lw=2)\n",
    "    plt.fill_between(x, 0, y, alpha=0.2, color=lines[0].get_c())\n",
    "    plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''To get pdf for beta distribution\n",
    "PDF is a function, whose value at any given sample (or point) in the sample space \n",
    "(the set of possible values taken by the random variable) can be interpreted as providing \n",
    "a relative likelihood that the value of the random variable would equal that sample.\n",
    "'''\n",
    "def get_pdf(x, site):\n",
    "    ''' \n",
    "    Parameters\n",
    "    -----------\n",
    "    x : Array of x values\n",
    "    site : Array cooresponding to the site in question\n",
    "\n",
    "    Returns\n",
    "    --------\n",
    "    numpy array\n",
    "    '''\n",
    "    alpha = sum(site)\n",
    "    beta = len(site) - alpha\n",
    "    return scs.beta(a=alpha, b=beta).pdf(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by looking only at converstion rate for old price. We assume a uniform prior, i.e., probability of 0 or 1 equally likely. Specifically, we use a beta distribution with alpha=1 and beta=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a bunch of different plots at once\n",
    "features=[#column names go in here]\n",
    "fig=plt.subplots(figsize=(10,15))\n",
    "for i, j in enumerate(features):\n",
    "    plt.subplot(4, 2, i+1)\n",
    "    plt.subplots_adjust(hspace = 1.0)\n",
    "    sns.countplot(x=j,df)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.title(\"Title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
